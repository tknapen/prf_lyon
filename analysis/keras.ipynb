{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/knapen/software/miniconda3/envs/py36/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, json\n",
    "import nibabel as nb\n",
    "\n",
    "from keras import metrics \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LocallyConnected1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "base_dir = '/home/knapen/projects/prf_lyon/'\n",
    "os.chdir(base_dir)\n",
    "\n",
    "os.chdir(os.path.join(base_dir, 'analysis'))\n",
    "from prf_fit import *\n",
    "\n",
    "with open(os.path.join(base_dir, 'analysis', 'settings.json')) as f:\n",
    "    json_s = f.read()\n",
    "    analysis_info = json.loads(json_s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "sub = 'sub-01'\n",
    "\n",
    "input_file = os.path.join(base_dir, 'data', sub, 'func', \\\n",
    "    sub+'_task-prf_acq-median_T1w_desc-preproc_bold.nii.gz')\n",
    "dm_file = os.path.join(base_dir, 'data', sub, 'dm_out.npy')\n",
    "    \n",
    "mask_file = nb.load(os.path.join(base_dir, 'data', sub, 'func', \\\n",
    "     sub+'_task-prf_dir-AP_run-1_space-T1w_desc-brain_mask.nii.gz'))\n",
    "mask = mask_file.get_data().astype(bool)\n",
    "\n",
    "# for registration into pycortex\n",
    "example_epi_file = os.path.join(base_dir, 'data', sub, 'func', \\\n",
    "     sub+'_task-prf_dir-AP_run-1_space-T1w_boldref.nii.gz')\n",
    "T1_file = os.path.join(base_dir, 'data', sub, 'anat', \\\n",
    "     sub+'_desc-preproc_T1w.nii.gz')\n",
    "fs_T1_file = os.path.join(base_dir, 'data', sub, 'anat', \\\n",
    "     'T1.nii.gz')\n",
    "\n",
    "#design matrix\n",
    "visual_dm = np.load(dm_file).T\n",
    "\n",
    "# data\n",
    "in_file_nii = nb.load(input_file)\n",
    "data = in_file_nii.get_data().reshape((-1,in_file_nii.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "fit_model = analysis_info[\"fit_model\"]\n",
    "N_PROCS = 8\n",
    "\n",
    "# Fit: define search grids\n",
    "x_grid_bound = (-analysis_info[\"max_eccen\"], analysis_info[\"max_eccen\"])\n",
    "y_grid_bound = (-analysis_info[\"max_eccen\"], analysis_info[\"max_eccen\"])\n",
    "sigma_grid_bound = (analysis_info[\"min_size\"], analysis_info[\"max_size\"])\n",
    "n_grid_bound = (analysis_info[\"min_n\"], analysis_info[\"max_n\"])\n",
    "grid_steps = analysis_info[\"grid_steps\"]\n",
    "\n",
    "# Fit: define search bounds\n",
    "x_fit_bound = (-analysis_info[\"max_eccen\"]*2, analysis_info[\"max_eccen\"]*2)\n",
    "y_fit_bound = (-analysis_info[\"max_eccen\"]*2, analysis_info[\"max_eccen\"]*2)\n",
    "sigma_fit_bound = (1e-6, 1e2)\n",
    "n_fit_bound = (1e-6, 2)\n",
    "beta_fit_bound = (-1e6, 1e6)\n",
    "baseline_fit_bound = (-1e6, 1e6)\n",
    "\n",
    "if fit_model == 'gauss' or fit_model == 'gauss_sg':\n",
    "    bound_grids  = (x_grid_bound, y_grid_bound, sigma_grid_bound)\n",
    "    bound_fits = (x_fit_bound, y_fit_bound, sigma_fit_bound, beta_fit_bound, baseline_fit_bound)\n",
    "elif fit_model == 'css' or fit_model == 'css_sg':\n",
    "    bound_grids  = (x_grid_bound, y_grid_bound, sigma_grid_bound, n_grid_bound)\n",
    "    bound_fits = (x_fit_bound, y_fit_bound, sigma_fit_bound, n_fit_bound, beta_fit_bound, baseline_fit_bound)\n",
    "\n",
    "# intitialize prf analysis\n",
    "prf = PRF_fit(  data = data[mask.ravel()],\n",
    "                fit_model = fit_model, \n",
    "                visual_design = visual_dm, \n",
    "                screen_distance = analysis_info[\"screen_distance\"],\n",
    "                screen_width = analysis_info[\"screen_width\"],\n",
    "                scale_factor = 1/2.0, \n",
    "                tr =  analysis_info[\"TR\"],\n",
    "                bound_grids = bound_grids,\n",
    "                grid_steps = grid_steps,\n",
    "                bound_fits = bound_fits,\n",
    "                n_jobs = N_PROCS,\n",
    "                sg_filter_window_length = analysis_info[\"sg_filt_window_length\"],\n",
    "                sg_filter_polyorder = analysis_info[\"sg_filt_polyorder\"],\n",
    "                sg_filter_deriv = analysis_info[\"sg_filt_deriv\"], \n",
    "                )\n",
    "# will need to move/delete this file for new predictions\n",
    "prediction_file = os.path.join(base_dir, 'data', 'sub-01', 'predictions.npy')\n",
    "if os.path.isfile(prediction_file):\n",
    "    prf.load_grid_predictions(prediction_file=prediction_file)\n",
    "else:\n",
    "    prf.make_predictions(out_file=prediction_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "blow_up = 100\n",
    "# make extra predictions, with added noise\n",
    "blow_up_noisy_predictions = np.repeat(prf.predictions, blow_up, axis=1)\n",
    "# scale predictions randomly\n",
    "betas = np.random.rand(blow_up_noisy_predictions.shape[1])+0.25\n",
    "blow_up_noisy_predictions *= betas\n",
    "# random offsets\n",
    "offsets = np.random.randn(blow_up_noisy_predictions.shape[1])\n",
    "blow_up_noisy_predictions += offsets\n",
    "\n",
    "blow_up_noisy_predictions += np.random.randn(prf.predictions.shape[0], prf.predictions.shape[1] * blow_up)/5.0\n",
    "\n",
    "extra_parameters = np.array([betas, offsets])\n",
    "\n",
    "n_prf_parameters = 5\n",
    "parameters = np.array([prf.prf_xs, prf.prf_ys, prf.prf_sigma]).reshape((3,-1))\n",
    "\n",
    "blow_up_parameters = np.vstack((np.repeat(parameters, blow_up, axis=1), extra_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 164, 83)           415       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 82, 83)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 79, 41)            13653     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 39, 41)            0         \n",
      "_________________________________________________________________\n",
      "locally_connected1d_7 (Local (None, 32, 20)            210560    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 16, 20)            0         \n",
      "_________________________________________________________________\n",
      "locally_connected1d_8 (Local (None, 9, 10)             14490     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 2, 10)             0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 239,383\n",
      "Trainable params: 239,383\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "Epoch 2/10\n",
      "Epoch 3/10\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "Epoch 9/10\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd57aae9630>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=prf.n_timepoints//2, kernel_size=4, input_shape=(prf.n_timepoints,1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=prf.n_timepoints//4, kernel_size=4, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LocallyConnected1D(filters=prf.n_timepoints//8, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LocallyConnected1D(filters=prf.n_timepoints//16, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "# model.add(Conv1D(filters=prf.n_timepoints//32, kernel_size=16, activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_prf_parameters*2, kernel_initializer='uniform'))\n",
    "model.add(Dense(n_prf_parameters))\n",
    "\n",
    "print(model.summary())\n",
    "plot_model(model, show_shapes=True, to_file='keras_1.pdf')\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='nadam',\n",
    "              metrics=['mae'])\n",
    "# model.fit(prf.predictions.T[:,:,np.newaxis], parameters.T, epochs=10, batch_size=32, verbose=3)\n",
    "model.fit(blow_up_noisy_predictions.T[:,:,np.newaxis], blow_up_parameters.T, \n",
    "          epochs=10, \n",
    "          batch_size=256, \n",
    "          verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "output_pars = model.predict(prf.data[:,:,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.99833249407842617, 0.0)\n"
     ]
    }
   ],
   "source": [
    "parameters = np.array([prf.prf_xs, prf.prf_ys, prf.prf_sigma, np.ones_like(prf.prf_sigma), np.zeros_like(prf.prf_sigma) ]).reshape((5,-1))\n",
    "pred = model.predict(prf.predictions.T[:,:,np.newaxis])\n",
    "\n",
    "print(sp.stats.pearsonr(pred.ravel(), parameters.T[:].ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(prf.predictions.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "py36"
  },
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
